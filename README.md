# Building Generative AI Agents with LangChain, Amazon Bedrock, Amazon DynamoDB, Amazon Kendra, and Amazon Lex. 
---

## Content
- [Overview](#overview)
- [Solution Architecture](#solution-architecture)
- [Agent Architecture](#agent-architecture)
- [Deployment Guide](#deployment-guide)
- [Testing and Validation](#testing-and-validation)
- [Clean Up](#clean-up)

## Overview
Generative AI Agents are capable of producing human-like responses and engaging in natural language conversations by orchestrating a chain of calls to Large Language Models (LLMs) and other augmenting tools based on user input. Instead of only fulfilling pre-defined intents through a static decision tree, Agents are autonomous within the context of their suite of available tools. 

This sample solution creates a Generative AI-powered Financial Services Agent that can assist users with finding their account information, completing a loan application, or answering any natural language question while also sourcing links for the provided answers. [Amazon Lex](https://docs.aws.amazon.com/lexv2/latest/dg/what-is.html) supplies the Natural Language Understanding (NLU) and Natural Language Processing (NLP) interface for the open-source [LangChain Conversational Agent](https://python.langchain.com/docs/modules/agents/agent_types/chat_conversation_agent) within an [AWS Amplify](https://docs.aws.amazon.com/amplify/latest/userguide/welcome.html) website. The Agent is equipped with tools that include an Anthropic Claude LLM hosted on [Amazon Bedrock](https://aws.amazon.com/bedrock/) and synthetic customer data stored on [Amazon DynamoDB](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html) and [Amazon Kendra](https://docs.aws.amazon.com/kendra/latest/dg/what-is-kendra.html).

This solution is intended to act as a launchpad for developers to create their own personalized conversational agents for various applications, such as chatbots, virtual assistants, and customer support systems.

### Demo Recording
[<img src="design/thumbnail.png" width="100%">](https://www.youtube.com/watch?v=bv4XV7epeik "Building Generative AI Agents with Amazon Bedrock, Amazon Lex, and LangChain - YouTube")

## Solution Architecture

Users perform natural dialog with the Agent through their choice of Web, SMS, or Voice channels. The Web channel includes an AWS Amplify hosted website with an Amazon Lex embedded chatbot for an example customer, Octank Financial. Each user request is processed by Lex which invokes an [AWS Lambda](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) handler for intent fulfillment. 

Lambda instruments the Financial Services Agent as a LangChain Conversational Agent that can access customer-specific data stored on DynamoDB, curate opinionated responses using customer documents and webpages indexed by Kendra, and provide general knowledge answers through a Large Language Model hosted on Bedrock. 

Responses generated by Kendra will include source links with octankfinancial.com as the root domain, demonstrating how the customer can configure the [Kendra Web Crawler](https://docs.aws.amazon.com/kendra/latest/dg/data-source-web-crawler.html) with their own domain to serve opinionated, proprietary responses. Otherwise, source links are served from the Bedrock LLM's training dataset.

<p align="center">
  <img src="design/solution-overview.svg">
  <em>Diagram 1: Solution Architecture Overview</em>
</p>

- **Provide Personalized Responses:** Query DynamoDB for customer account information, such as mortgage summary details, next payment date, and balance due.
- **Curate Opinionated Answers:** Inform Agent responses using a Kendra Index configured with authoritative data sources: customer documents stored in [Amazon Simple Storage Service (S3)](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html) and Web Crawlers configured for the customer's website.
- **Access General Knowledge:** Harness the vast amounts of data used to pre-train the different LLMs hosted on Bedrock to produce replies for any customer prompt.

## Agent Architecture

The LangChain Conversational Agent incorporates conversation memory so it can respond to multiple queries with contextual generation. Our Agent leverages [LangChain's DynamoDB Chat Message History class](https://python.langchain.com/docs/modules/memory/integrations/dynamodb_chat_message_history) as a conversation memory buffer so it can recall past interactions and enhance the user experience with more meaningful, context-aware responses.

The Agent's brain is an Anthropic Claude LLM hosted on Bedrock, which allows the Agent to complete the desired task through a series of carefully crafted text inputs known as prompts. The primary objective of prompt engineering is to elicit specific and accurate responses from the LLM. Different prompt engineering techniques include:

- **Zero-Shot:** A single question is presented to the model without any additional clues. The model is expected to generate a response based solely on the given question.

- **Few-Shot:** A set of sample questions and their corresponding answers before presenting the actual question. By exposing the model to these examples, it learns to respond in a similar manner.

- **Chain-of-Thought:** A specific style of few-shot prompting where the prompt is designed to contain a series of intermediate reasoning steps, guiding the model through a logical thought process, ultimately leading to the desired answer.

Our Agent utilizes chain-of-thought reasoning by executing a set of _Actions_ upon receiving a request. Following each _Action_, the Agent enters the _Observation_ step, where it expresses a _Thought_. If a _Final Answer_ is not yet achieved, the Agent iterates, selecting different _Actions_ to progress towards reaching the _Final Answer_.

~~~~
Thought: Do I need to use a tool? Yes
Action: The action to take
Action Input: The input to the action
Observation: The result of the action

Thought: Do I need to use a tool? No
FSI Agent: [answer and source documents]
~~~~

As part of the Agent's different reasoning paths and self-evaluating choices to decide the next course of action, it can access synthetic customer data sources through an [Amazon Kendra Index Retriever tool](https://python.langchain.com/docs/modules/data_connection/retrievers/integrations/amazon_kendra_retriever). Using Kendra, the Agent can perform contextual search across a wide range of content types, including documents, FAQs, knowledge bases, manuals, and websites - Please refer to the list of [Kendra supported Data Sources](https://docs.aws.amazon.com/kendra/latest/dg/hiw-data-source.html). The Agent can use this tool to provide opinionated responses to user prompts that should be answered using an authoritative, customer-provided knowledge base, instead of the more general knowledge corpus used to pretrain the Bedrock LLM.

<p align="center">
  <img src="design/agent.svg">
  <em>Diagram 2: LangChain Conversational Agent Architecture</em>
</p>

**Sample Prompts:** 
* Why should I use Octank Financial?
* How competitive are their rates?
* Which type of mortgage should I use?
* What are current mortgage trends?
* How much do I need saved for a down payment?
* What other costs will I pay at closing?

## Deployment Guide
see [Deployment Guide](documentation/deployment-guide.md)

## Testing and Validation
see [Testing and Validation](documentation/testing-and-validation.md)

## Clean Up
see [Clean Up](documentation/clean-up.md)

---

Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
SPDX-License-Identifier: MIT-0
